{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T20:35:39.465004Z",
     "iopub.status.busy": "2024-11-29T20:35:39.464651Z",
     "iopub.status.idle": "2024-11-29T20:35:39.486129Z",
     "shell.execute_reply": "2024-11-29T20:35:39.485294Z",
     "shell.execute_reply.started": "2024-11-29T20:35:39.464973Z"
    },
    "id": "CO6_Ft_8T56A",
    "outputId": "2745e3fa-5247-45b0-e18d-1154073e693e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as tfk\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers as tfkl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {tfk.__version__}\")\n",
    "print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## ⏳ Load the Data (no outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/kaggle/input/an2dl-hw2-clean\")\n",
    "if not DATA_ROOT.exists():\n",
    "    DATA_ROOT = Path().absolute().parent / \"data\" / \"clean\"\n",
    "\n",
    "DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T20:35:39.490323Z",
     "iopub.status.busy": "2024-11-29T20:35:39.489454Z",
     "iopub.status.idle": "2024-11-29T20:35:40.823805Z",
     "shell.execute_reply": "2024-11-29T20:35:40.822304Z",
     "shell.execute_reply.started": "2024-11-29T20:35:39.490280Z"
    },
    "id": "pLaoDaG1V1Yg",
    "outputId": "bb25d295-d8ea-4786-e03b-aa98511f5c9b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with np.load(DATA_ROOT / \"train.npz\") as data:\n",
    "    X_train = data[\"x\"]\n",
    "    y_train = data[\"y\"]\n",
    "with np.load(DATA_ROOT / \"test.npz\") as data:\n",
    "    X_test = data[\"x\"]\n",
    "\n",
    "print(f\"Training X shape: {X_train.shape}\")\n",
    "print(f\"Training y shape: {y_train.shape}\")\n",
    "print(f\"Test X shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSliIxBvbs2Q"
   },
   "source": [
    "## 🛠️ Train and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T20:35:42.164877Z",
     "iopub.status.busy": "2024-11-29T20:35:42.164567Z",
     "iopub.status.idle": "2024-11-29T20:35:43.461438Z",
     "shell.execute_reply": "2024-11-29T20:35:43.460426Z",
     "shell.execute_reply.started": "2024-11-29T20:35:42.164849Z"
    },
    "id": "VmnTgJi_OOs1",
    "outputId": "68fce9f8-c1e0-4c68-cadc-d7a447c3c53a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add color channel and rescale pixels between 0 and 1\n",
    "X_train = X_train[..., np.newaxis] / 255.0\n",
    "X_test = X_test[..., np.newaxis] / 255.0\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the input shape for both images and masks is correct\n",
    "X_train = np.squeeze(X_train)  # Remove any singleton dimensions\n",
    "y_train = np.squeeze(y_train)  # Remove any singleton dimensions\n",
    "\n",
    "# Check if the channel dimension exists, otherwise add it\n",
    "if X_train.ndim == 3:  # If missing the channel dimension, add it\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "\n",
    "if y_train.ndim == 3:  # Ensure y_train has the correct shape\n",
    "    y_train = y_train[..., np.newaxis]\n",
    "\n",
    "print(f\"Shape of X_train after reshaping: {X_train.shape}\")\n",
    "print(f\"Shape of y_train after reshaping: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T20:35:43.462958Z",
     "iopub.status.busy": "2024-11-29T20:35:43.462580Z",
     "iopub.status.idle": "2024-11-29T20:35:43.468075Z",
     "shell.execute_reply": "2024-11-29T20:35:43.467236Z",
     "shell.execute_reply.started": "2024-11-29T20:35:43.462918Z"
    },
    "id": "7f-GclnBATL3",
    "outputId": "911310d9-104f-4a10-f138-ee098513fa77",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train to integers for class count\n",
    "y_train_int = y_train.astype(np.int32)\n",
    "\n",
    "# Calculate class weights based on pixel proportions\n",
    "class_pixel_counts = np.bincount(\n",
    "    y_train_int.flatten(), minlength=num_classes\n",
    ")  # Count pixels for each class\n",
    "total_pixels = np.sum(class_pixel_counts)  # Total number of pixels\n",
    "class_weights = total_pixels / (class_pixel_counts + 1e-6)  # Inverse frequency\n",
    "class_weights /= np.sum(class_weights)  # Normalize to sum to 1\n",
    "\n",
    "print(f\"Class pixel counts: {class_pixel_counts}\")\n",
    "print(f\"Calculated class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T20:35:43.479202Z",
     "iopub.status.busy": "2024-11-29T20:35:43.478926Z",
     "iopub.status.idle": "2024-11-29T20:35:43.489944Z",
     "shell.execute_reply": "2024-11-29T20:35:43.489265Z",
     "shell.execute_reply.started": "2024-11-29T20:35:43.479177Z"
    },
    "id": "GUdBWfPIEreS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom callback for visualization\n",
    "class VisualizeSegmentationCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_train, y_train, num_images=2):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.num_images = num_images\n",
    "        self.selected_indices = []\n",
    "\n",
    "        # Identify images containing at least 4 classes\n",
    "        for i in range(len(y_train)):\n",
    "            if len(np.unique(y_train[i])) >= 4:  # Check for at least 4 classes\n",
    "                self.selected_indices.append(i)\n",
    "            if len(self.selected_indices) == num_images:\n",
    "                break\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Plot predictions for the selected images\n",
    "        fig, axes = plt.subplots(self.num_images, 3, figsize=(15, self.num_images * 5))\n",
    "\n",
    "        for idx, i in enumerate(self.selected_indices):\n",
    "            # Extract image and ground truth\n",
    "            X_sample = self.X_train[i : i + 1]  # Add batch dimension\n",
    "            y_sample = self.y_train[i]\n",
    "\n",
    "            # Predict on the image\n",
    "            predicted_mask = self.model.predict(X_sample)\n",
    "            predicted_mask = np.argmax(predicted_mask, axis=-1)[\n",
    "                0\n",
    "            ]  # Convert to class labels\n",
    "\n",
    "            # Visualize the input, ground truth, and predicted mask\n",
    "            axes[idx, 0].imshow(X_sample[0].squeeze(), cmap=\"gray\")\n",
    "            axes[idx, 0].set_title(\"Input Image\")\n",
    "            axes[idx, 0].axis(\"off\")\n",
    "\n",
    "            axes[idx, 1].imshow(y_sample, cmap=\"viridis\")\n",
    "            axes[idx, 1].set_title(\"Ground Truth Mask\")\n",
    "            axes[idx, 1].axis(\"off\")\n",
    "\n",
    "            axes[idx, 2].imshow(predicted_mask, cmap=\"viridis\")\n",
    "            axes[idx, 2].set_title(f\"Predicted Mask (Epoch {epoch + 1})\")\n",
    "            axes[idx, 2].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNNFRiILMgYZ"
   },
   "source": [
    "## Adding advanced tecnics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T20:35:43.984156Z",
     "iopub.status.busy": "2024-11-29T20:35:43.983860Z",
     "iopub.status.idle": "2024-11-29T21:05:06.820521Z",
     "shell.execute_reply": "2024-11-29T21:05:06.819402Z",
     "shell.execute_reply.started": "2024-11-29T20:35:43.984128Z"
    },
    "id": "qJFugEI3qxgH",
    "outputId": "10e2e70f-e773-4c31-f987-08c0e9ad7a10",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Residual Block\n",
    "def residual_block(x, filters):\n",
    "    shortcut = x\n",
    "    x = tfkl.Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tfkl.Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    shortcut = tfkl.Conv2D(filters, (1, 1), padding=\"same\")(shortcut)\n",
    "    return tfkl.add([x, shortcut])\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # Remove the extra dimension from y_true using tf.squeeze\n",
    "        y_true = tf.squeeze(y_true, axis=-1)\n",
    "\n",
    "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=len(weights))\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "        return -tf.reduce_sum(y_true * tf.math.log(y_pred) * weights, axis=-1)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=(1, 2, 3))\n",
    "    # Calculate Dice loss per image in the batch\n",
    "    dice_loss_per_image = 1 - numerator / (denominator + tf.keras.backend.epsilon())\n",
    "    # Return the mean Dice loss across the batch\n",
    "    return tf.reduce_mean(dice_loss_per_image)\n",
    "\n",
    "\n",
    "# Hybrid Loss Function\n",
    "def combined_loss(weights):\n",
    "    ce_loss = weighted_categorical_crossentropy(weights)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # Calculate losses\n",
    "        ce_loss_value = ce_loss(y_true, y_pred)\n",
    "        dice_loss_value = dice_loss(y_true, y_pred)\n",
    "        # Return the sum of the two losses\n",
    "        return ce_loss_value + dice_loss_value\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# U-Net with Residual Connections\n",
    "def unet_with_residual_blocks(input_shape, num_classes):\n",
    "    inputs = tfkl.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = residual_block(inputs, 64)\n",
    "    p1 = tfkl.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = residual_block(p1, 128)\n",
    "    p2 = tfkl.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = residual_block(p2, 256)\n",
    "    p3 = tfkl.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = residual_block(p3, 512)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = tfkl.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=\"same\")(c4)\n",
    "    u1 = tfkl.concatenate([u1, c3])\n",
    "    d1 = residual_block(u1, 256)\n",
    "\n",
    "    u2 = tfkl.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(d1)\n",
    "    u2 = tfkl.concatenate([u2, c2])\n",
    "    d2 = residual_block(u2, 128)\n",
    "\n",
    "    u3 = tfkl.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(d2)\n",
    "    u3 = tfkl.concatenate([u3, c1])\n",
    "    d3 = residual_block(u3, 64)\n",
    "\n",
    "    outputs = tfkl.Conv2D(num_classes, (1, 1), activation=\"softmax\")(d3)\n",
    "\n",
    "    return tfk.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "input_shape = X_train.shape[1:]\n",
    "loss = combined_loss(class_weights)\n",
    "model = unet_with_residual_blocks(input_shape, num_classes)\n",
    "model.compile(\n",
    "    optimizer=tfk.optimizers.AdamW(learning_rate=1e-4),\n",
    "    loss=loss,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tfk.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",  # Monitor loss instead of validation loss\n",
    "    patience=30,\n",
    "    restore_best_weights=True,\n",
    "    min_delta=1e-4,  # Minimum change to qualify as an improvement\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "reduce_lr = tfk.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\",  # Monitor loss instead of validation loss\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "visualize_callback = VisualizeSegmentationCallback(X_train, y_train)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping, reduce_lr, visualize_callback],\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T21:05:06.822356Z",
     "iopub.status.busy": "2024-11-29T21:05:06.821954Z",
     "iopub.status.idle": "2024-11-29T21:05:07.204877Z",
     "shell.execute_reply": "2024-11-29T21:05:07.203893Z",
     "shell.execute_reply.started": "2024-11-29T21:05:06.822316Z"
    },
    "id": "PtM0ubgdOzG-",
    "outputId": "7d24f8db-e307-456a-a176-fa0b4919ec78",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_filename = \"model.keras\"\n",
    "model.save(model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNp6pUZuddqC"
   },
   "source": [
    "## 📊 Prepare Your Submission\n",
    "\n",
    "In our Kaggle competition, submissions are made as `csv` files. To create a proper `csv` file, you need to flatten your predictions and include an `id` column as the first column of your dataframe. To maintain consistency between your results and our solution, please avoid shuffling the test set. The code below demonstrates how to prepare the `csv` file from your model predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T21:05:07.212925Z",
     "iopub.status.busy": "2024-11-29T21:05:07.212682Z",
     "iopub.status.idle": "2024-11-29T21:05:07.220684Z",
     "shell.execute_reply": "2024-11-29T21:05:07.219798Z",
     "shell.execute_reply.started": "2024-11-29T21:05:07.212901Z"
    },
    "id": "0vxbHD-BKEJP",
    "outputId": "4d41a974-4969-42a5-928f-2c9dd4a4e3cf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"X_test shape before reshaping: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T21:05:07.221961Z",
     "iopub.status.busy": "2024-11-29T21:05:07.221710Z",
     "iopub.status.idle": "2024-11-29T21:05:32.132858Z",
     "shell.execute_reply": "2024-11-29T21:05:32.131894Z",
     "shell.execute_reply.started": "2024-11-29T21:05:07.221936Z"
    },
    "id": "2ZDIzVsVKKa0",
    "outputId": "7ae88f38-6274-49b4-d5c9-a8f2664e7c52",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "preds = model.predict(X_test)\n",
    "preds = np.argmax(preds, axis=-1)  # Convert probabilities to class labels\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T21:05:32.518200Z",
     "iopub.status.busy": "2024-11-29T21:05:32.517935Z",
     "iopub.status.idle": "2024-11-29T21:05:36.703770Z",
     "shell.execute_reply": "2024-11-29T21:05:36.702906Z",
     "shell.execute_reply.started": "2024-11-29T21:05:32.518174Z"
    },
    "id": "UUz9tJyvCrfz",
    "outputId": "959018fc-8b0d-48a5-ddb0-fb7c0c2c938e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "# Randomly select 20 indices for prediction\n",
    "random_indices = np.random.choice(X_test.shape[0], size=20, replace=False)\n",
    "print(f\"Randomly selected indices for prediction (seed=42): {random_indices}\")\n",
    "\n",
    "# Select 20 random samples and their corresponding masks\n",
    "X_sample = X_test[random_indices]\n",
    "\n",
    "\n",
    "predicted_masks = preds\n",
    "\n",
    "# Visualize the predictions\n",
    "num_images = len(X_sample)  # Number of images to visualize\n",
    "fig, axes = plt.subplots(num_images, 2, figsize=(15, num_images * 5))\n",
    "\n",
    "for i in range(num_images):\n",
    "    # Original Image\n",
    "    ax_img = axes[i, 0]\n",
    "    ax_img.imshow(X_sample[i].squeeze(), cmap=\"gray\")\n",
    "    ax_img.set_title(\"Input Image\")\n",
    "    ax_img.axis(\"off\")\n",
    "\n",
    "    # Predicted Mask\n",
    "    ax_pred = axes[i, 1]\n",
    "    ax_pred.imshow(predicted_masks[i], cmap=\"viridis\")\n",
    "    ax_pred.set_title(\"Predicted Mask\")\n",
    "    ax_pred.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T21:05:36.705401Z",
     "iopub.status.busy": "2024-11-29T21:05:36.705046Z",
     "iopub.status.idle": "2024-11-29T21:05:36.711896Z",
     "shell.execute_reply": "2024-11-29T21:05:36.711086Z",
     "shell.execute_reply.started": "2024-11-29T21:05:36.705365Z"
    },
    "id": "SPjMEKqZW5jX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def y_to_df(y) -> pd.DataFrame:\n",
    "    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n",
    "    n_samples = len(y)\n",
    "    y_flat = y.reshape(n_samples, -1)\n",
    "    df = pd.DataFrame(y_flat)\n",
    "    df[\"id\"] = np.arange(n_samples)\n",
    "    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "execution": {
     "iopub.execute_input": "2024-11-29T21:05:36.713279Z",
     "iopub.status.busy": "2024-11-29T21:05:36.712952Z",
     "iopub.status.idle": "2024-11-29T21:05:59.110653Z",
     "shell.execute_reply": "2024-11-29T21:05:59.109495Z",
     "shell.execute_reply.started": "2024-11-29T21:05:36.713236Z"
    },
    "id": "s18kX1uDconq",
    "outputId": "a9eb8b5b-5f59-4220-8e15-0a26a810ec25",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create and download the csv submission file\n",
    "submission_filename = \"submission.csv\"\n",
    "submission_df = y_to_df(preds)\n",
    "submission_df.to_csv(submission_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-11-29T21:05:59.111282Z",
     "iopub.status.idle": "2024-11-29T21:05:59.111568Z",
     "shell.execute_reply": "2024-11-29T21:05:59.111445Z",
     "shell.execute_reply.started": "2024-11-29T21:05:59.111430Z"
    },
    "id": "CFhlYeiVf_UZ",
    "outputId": "93425a14-5d22-4eb2-c958-7c5bbb93efd1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(submission_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-11-29T21:05:59.112705Z",
     "iopub.status.idle": "2024-11-29T21:05:59.113055Z",
     "shell.execute_reply": "2024-11-29T21:05:59.112873Z",
     "shell.execute_reply.started": "2024-11-29T21:05:59.112858Z"
    },
    "id": "KKnZEWbug5o9",
    "outputId": "2db98efc-9db4-49f1-a04a-23b0712461e8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(submission_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6194527,
     "sourceId": 10053265,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
